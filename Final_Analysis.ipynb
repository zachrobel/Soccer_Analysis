{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lnWTujDfDaop",
        "soGAQDh9Ff2r",
        "QLty-VTtHE99",
        "3r8BsiqdZu0F",
        "SF1IdqDD6pST",
        "FQO-zVJV7i3N",
        "RNEAp5CY8fBL"
      ],
      "authorship_tag": "ABX9TyMVuaMMu7nzM21l8mCtz+Qo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachrobel/Soccer_Analysis/blob/main/Final_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Analysis\n",
        "----\n",
        "Initializes a YOLO object detection model. The original model is only partially accurate. Most detections are largely irrelevant for project desires.\n"
      ],
      "metadata": {
        "id": "lnWTujDfDaop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "!pip install supervision"
      ],
      "metadata": {
        "id": "2vipTEMPEoDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK1AiCZFDNeq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8x')\n",
        "\n",
        "results = model.predict('Soccer1.mp4', save=True)\n",
        "print(results[0])\n",
        "print('===============================')\n",
        "\n",
        "for box in results[0].boxes:\n",
        "  print(box)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Dataset\n",
        "---\n",
        "Uses Roboflow for dataset management and preparation with the YOLOv5 model for object detection training. It accessing labeled datasets from Roboflow, organizing data for model training, and configuring training parameters for YOLOv5."
      ],
      "metadata": {
        "id": "soGAQDh9Ff2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Zc10kKvu944d9TXcsnXx\")\n",
        "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")"
      ],
      "metadata": {
        "id": "yygkfQuEGEGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.move('football-players-detection-1/train', 'football-players-detection-1/football-players-detection-1/train')\n",
        "shutil.move('football-players-detection-1/test', 'football-players-detection-1/football-players-detection-1/test')\n",
        "shutil.move('football-players-detection-1/valid', 'football-players-detection-1/football-players-detection-1/valid')\n"
      ],
      "metadata": {
        "id": "XamEV76nGmZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "---\n",
        "The parameter epochs=100 specifies that the YOLOv5 model will be trained for 100 epochs, meaning it will go through the entire training dataset 100 times during the training process"
      ],
      "metadata": {
        "id": "QLty-VTtHE99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov5lu.pt data={dataset.location}/data.yaml epochs=100 imgsz=640\n"
      ],
      "metadata": {
        "id": "y9rFCGAEHHf6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updated Model Detection\n",
        "---\n",
        "The new model is implemented here. The next steps will focus on utilizing the upgraded detections"
      ],
      "metadata": {
        "id": "JzopuhFEQlQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('best-4.pt')\n",
        "\n",
        "results = model.predict('Soccer1.mp4', save=True)\n",
        "print(results[0])\n",
        "print('===============================')\n",
        "\n",
        "for box in results[0].boxes:\n",
        "  print(box)\n"
      ],
      "metadata": {
        "id": "Idi6fpPCQi9d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Utils\n",
        "---\n",
        "Takes the path to a video file (video_path) as input. Initializes a VideoCapture object using OpenCV to read frames from the specified video . Iterates through each frame in the video using a while loop. For each iteration, it reads the next frame using the read method. If a frame is successfully read (ret is True), it appends the frame to the frames list. If no frame is read (i.e., ret is False, indicating the end of the video), the loop breaks. Returns the list of frames read from the video.\n",
        "\n",
        "Takes a list of video frames (output_video_frames) and the desired output path (output_video_path) as input. Initializes VideoWriter object using OpenCV, specifying the output video path, codec (XVID), frame rate (24 frames per second), and frame size (same as the size of the first frame in output_video_frames). Iterates through each frame in output_video_frames, writes each frame to the output video using the write method of the out object, and finally releases the video."
      ],
      "metadata": {
        "id": "3r8BsiqdZu0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "Y9_6dWRzZ0Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def read_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    return frames"
      ],
      "metadata": {
        "id": "yy0ICvLkZ8tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video(ouput_video_frames,output_video_path):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 24, (ouput_video_frames[0].shape[1], ouput_video_frames[0].shape[0]))\n",
        "    for frame in ouput_video_frames:\n",
        "        out.write(frame)\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "HC7G0-fVakgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BBOX Utils\n",
        "----\n",
        "The get_center_of_bbox function takes a bounding box (bbox) as input.\n",
        "Calculates the center coordinates of the bounding box by taking the average of the x-coordinates (x1 and x2) and the average of the y-coordinates (y1 and y2). The coordinates (x_center, y_center) are returned as integers.\n",
        "\n",
        "The get_bbox_width function takes a bounding box (bbox) as input. It calculates the width of the bounding box by subtracting the x-coordinate of the top-left corner (bbox[0]) from the x-coordinate of the bottom-right corner (bbox[2]).\n",
        "\n",
        "The measure_distance function takes two points (p1 and p2) as input.\n",
        "It calculates the Euclidean distance between the two points using the distance formula."
      ],
      "metadata": {
        "id": "SF1IdqDD6pST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def get_center_of_bbox(bbox):\n",
        "    x1,y1,x2,y2 = bbox\n",
        "    return int((x1+x2)/2),int((y1+y2)/2)\n",
        "def get_bbox_width(bbox):\n",
        "    return bbox[2]-bbox[0]\n",
        "def measure_distance(p1,p2):\n",
        "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5"
      ],
      "metadata": {
        "id": "6gGxJV-U3duD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Team Assignment\n",
        "\n",
        "----\n",
        "\n",
        "The TeamAssigner class contains methods for assigning team colors to players based on their jersey colors.\n",
        "\n",
        "The get_player_color method is called for each player's bounding box.\n",
        "This method extracts the dominant color from the top half of the player's jersey using K-means clustering.\n",
        "K-means clustering is performed on the pixel values of the top half of the player's jersey image to identify the dominant colors.\n",
        "The cluster with the highest frequency is assumed to represent the player's team color.\n",
        "\n",
        "Once the dominant colors are extracted for all players, K-means clustering is applied again to cluster these colors into two groups, representing the two teams.\n",
        "The team colors are then assigned based on the centroids of these clusters.\n",
        "Each player is assigned to a team based on the proximity of their jersey color to the centroids of the team color clusters.\n",
        "\n",
        "For each player, their jersey color is compared to the centroids of the team color clusters.\n",
        "The player is assigned to the team whose centroid is closest to their jersey color.\n",
        "In cases where a player's jersey color is significantly different from both team colors, additional logic may be applied to handle such scenarios.\n"
      ],
      "metadata": {
        "id": "RNEAp5CY8fBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "class TeamAssigner:\n",
        "    def __init__(self):\n",
        "        self.team_colors = {}\n",
        "        self.player_team_dict = {}\n",
        "\n",
        "    def get_clustering_model(self,image):\n",
        "        # Reshape the image to 2D array\n",
        "        image_2d = image.reshape(-1,3)\n",
        "\n",
        "        # Preform K-means with 2 clusters\n",
        "        kmeans = KMeans(n_clusters=2, init=\"k-means++\",n_init=1)\n",
        "        kmeans.fit(image_2d)\n",
        "\n",
        "        return kmeans\n",
        "\n",
        "    def get_player_color(self,frame,bbox):\n",
        "        image = frame[int(bbox[1]):int(bbox[3]),int(bbox[0]):int(bbox[2])]\n",
        "\n",
        "        top_half_image = image[0:int(image.shape[0]/2),:]\n",
        "\n",
        "        # Get Clustering model\n",
        "        kmeans = self.get_clustering_model(top_half_image)\n",
        "\n",
        "        # Get the cluster labels forr each pixel\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Reshape the labels to the image shape\n",
        "        clustered_image = labels.reshape(top_half_image.shape[0],top_half_image.shape[1])\n",
        "\n",
        "        # Get the player cluster\n",
        "        corner_clusters = [clustered_image[0,0],clustered_image[0,-1],clustered_image[-1,0],clustered_image[-1,-1]]\n",
        "        non_player_cluster = max(set(corner_clusters),key=corner_clusters.count)\n",
        "        player_cluster = 1 - non_player_cluster\n",
        "\n",
        "        player_color = kmeans.cluster_centers_[player_cluster]\n",
        "\n",
        "        return player_color\n",
        "\n",
        "\n",
        "    def assign_team_color(self,frame, player_detections):\n",
        "\n",
        "        player_colors = []\n",
        "        for _, player_detection in player_detections.items():\n",
        "            bbox = player_detection[\"bbox\"]\n",
        "            player_color =  self.get_player_color(frame,bbox)\n",
        "            player_colors.append(player_color)\n",
        "\n",
        "        kmeans = KMeans(n_clusters=2, init=\"k-means++\",n_init=10)\n",
        "        kmeans.fit(player_colors)\n",
        "\n",
        "        self.kmeans = kmeans\n",
        "\n",
        "        self.team_colors[1] = kmeans.cluster_centers_[0]\n",
        "        self.team_colors[2] = kmeans.cluster_centers_[1]\n",
        "\n",
        "\n",
        "    def get_player_team(self,frame,player_bbox,player_id):\n",
        "        if player_id in self.player_team_dict:\n",
        "            return self.player_team_dict[player_id]\n",
        "\n",
        "        player_color = self.get_player_color(frame,player_bbox)\n",
        "\n",
        "        team_id = self.kmeans.predict(player_color.reshape(1,-1))[0]\n",
        "        team_id+=1\n",
        "\n",
        "        self.player_team_dict[player_id] = team_id\n",
        "\n",
        "        return team_id"
      ],
      "metadata": {
        "id": "6wJPO-Tl8i2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Color Assignment Logic\n"
      ],
      "metadata": {
        "id": "FQO-zVJV7i3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "HIcSkWkX7oJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"stubs/cropped_.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "KRTv-tfh7x0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axBz7e9H70pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_half_image=  image[0: int(image.shape[0]/2), :]\n",
        "plt.imshow(top_half_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yDaYmA-W72dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the image into 2d array\n",
        "image_2d = top_half_image.reshape(-1, 3)\n",
        "\n",
        "# perform k-means clustering with 2 clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=0)\n",
        "kmeans.fit(image_2d)\n",
        "\n",
        "# get the cluster labels\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# reshape the labels into the orginal image shape\n",
        "clustered_image = labels.reshape(top_half_image.shape[0], top_half_image.shape[1])\n",
        "\n",
        "# Display the clustered image\n",
        "plt.imshow(clustered_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y_jp8Yn775Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corner_clusters = [clustered_image[0, 0], clustered_image[0, -1], clustered_image[-1, 0], clustered_image[-1, -1]]\n",
        "non_player_cluster = max(set(corner_clusters), key=corner_clusters.count)\n",
        "print(non_player_cluster)"
      ],
      "metadata": {
        "id": "gB6_LBcX8T7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "player_cluster = 1-non_player_cluster\n",
        "print(player_cluster)"
      ],
      "metadata": {
        "id": "74QXJf9t8Qmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.cluster_centers_[player_cluster]"
      ],
      "metadata": {
        "id": "jiaaep7q8Ult"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Player Ball Assignment\n",
        "---\n",
        "\n",
        "Here, the bounding box of the ball is extracted from each frame of the video.\n",
        "\n",
        "For each player detected in the frame, the distance between the player's position (center of their bounding box) and the ball's position (center of its bounding box) is calculated.\n",
        "\n",
        "The player closest to the ball within a certain threshold distance (e.g., max_player_ball_distance) is considered to be in possession of the ball.\n",
        "If multiple players are within the threshold distance, the player closest to the ball is assigned possession.\n",
        "\n",
        "The assigned player's ID is recorded for each frame. If no player is within the threshold distance of the ball, the possession status is maintained from the previous frame.\n"
      ],
      "metadata": {
        "id": "CU4hoRajsORu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlayerBallAssigner():\n",
        "    def __init__(self):\n",
        "        self.max_player_ball_distance = 70\n",
        "\n",
        "    def assign_ball_to_player(self,players,ball_bbox):\n",
        "        ball_position = get_center_of_bbox(ball_bbox)\n",
        "\n",
        "        miniumum_distance = 99999\n",
        "        assigned_player=-1\n",
        "\n",
        "        for player_id, player in players.items():\n",
        "            player_bbox = player['bbox']\n",
        "\n",
        "            distance_left = measure_distance((player_bbox[0],player_bbox[-1]),ball_position)\n",
        "            distance_right = measure_distance((player_bbox[2],player_bbox[-1]),ball_position)\n",
        "            distance = min(distance_left,distance_right)\n",
        "\n",
        "            if distance < self.max_player_ball_distance:\n",
        "                if distance < miniumum_distance:\n",
        "                    miniumum_distance = distance\n",
        "                    assigned_player = player_id\n",
        "\n",
        "        return assigned_player"
      ],
      "metadata": {
        "id": "1Bg95LE9sSqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tracking\n",
        "---\n",
        "\n",
        "Takes the path to the YOLO model (model_path) as input and initializes a YOLO object for object detection.\n",
        "Additionally, it initializes a ByteTrack object from the supervision library for object tracking.\n",
        "\n",
        "Ball Position Interpolation (interpolate_ball_positions):\n",
        "\n",
        "The interpolate_ball_positions method takes a list of ball positions across frames (ball_positions) as input. It interpolates missing or inaccurate ball positions to ensure a smoother trajectory. Missing positions are filled by linear interpolation between adjacent known positions. The method returns a list of interpolated ball positions.\n",
        "\n",
        "Object Detection (detect_frames):\n",
        "\n",
        "The detect_frames method performs object detection on a batch of frames.\n",
        "It takes a list of frames as input and utilizes the YOLO model to detect objects within each frame. The method returns a list of detections, where each detection contains information about detected objects (bounding boxes, class labels, confidence scores, etc.).\n",
        "\n",
        "Object Tracking (get_object_tracks):\n",
        "\n",
        "The get_object_tracks method combines object detection results with object tracking to provide object tracks over multiple frames. It takes a list of frames (video_frames) as input along with optional parameters for reading from a stub and providing a stub path. It detects objects in each frame using the detect_frames method and then updates the object tracks using the ByteTrack object. The method returns tracks for players, referees, and the ball, containing information about their positions and identities across frames.\n",
        "\n",
        "Ellipse Drawing (draw_ellipse):\n",
        "\n",
        "The draw_ellipse method draws an ellipse around an object's bounding box.\n",
        "It takes parameters such as the frame, bounding box (bbox), color, and optional track ID. The method draws an ellipse around the bounding box using OpenCV's ellipse function and adds a rectangle and text for the track ID.\n",
        "\n",
        "Triangle Drawing (draw_triangle):\n",
        "\n",
        "The draw_triangle method draws a triangle above an object's bounding box to indicate possession (e.g., player with the ball). Similar to draw_ellipse, it takes parameters such as the frame, bounding box (bbox), and color. The method draws a triangle above the bounding box using OpenCV's drawContours function.\n",
        "\n",
        "Team Ball Control Visualization (draw_team_ball_control):\n",
        "\n",
        "The draw_team_ball_control method visualizes ball control statistics for each team. It takes parameters such as the frame, frame number, and team ball control statistics. The method overlays semi-transparent rectangles on the frame to display ball control percentages for each team.\n",
        "\n",
        "Annotations Drawing (draw_annotations):\n",
        "\n",
        "The draw_annotations method draws annotations (ellipses, triangles, team ball control visuals) on each frame. It takes a list of video frames (video_frames), object tracks (tracks), and team ball control statistics as input. The method iterates through each frame, draws annotations for players, referees, and the ball using the draw_ellipse, draw_triangle, and draw_team_ball_control methods, and returns a list of annotated frames."
      ],
      "metadata": {
        "id": "FBsb3FX6E4Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class Tracker:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.tracker = sv.ByteTrack()\n",
        "\n",
        "    def interpolate_ball_positions(self,ball_positions):\n",
        "        ball_positions = [x.get(1,{}).get('bbox',[]) for x in ball_positions]\n",
        "        df_ball_positions = pd.DataFrame(ball_positions,columns=['x1','y1','x2','y2'])\n",
        "\n",
        "        # Interpolate missing values\n",
        "        df_ball_positions = df_ball_positions.interpolate()\n",
        "        df_ball_positions = df_ball_positions.bfill()\n",
        "\n",
        "        ball_positions = [{1: {\"bbox\":x}} for x in df_ball_positions.to_numpy().tolist()]\n",
        "\n",
        "        return ball_positions\n",
        "\n",
        "\n",
        "    def detect_frames(self, frames):\n",
        "        batch_size=20\n",
        "        detections = []\n",
        "        for i in range(0,len(frames),batch_size):\n",
        "            detections_batch = self.model.predict(frames[i:i+batch_size],conf=0.1)\n",
        "            detections += detections_batch\n",
        "        return detections\n",
        "\n",
        "    def get_object_tracks(self, frames, read_from_stub=False, stub_path=None):\n",
        "\n",
        "        if read_from_stub and stub_path is not None and os.path.exists(stub_path):\n",
        "            with open(stub_path,'rb') as f:\n",
        "                tracks = pickle.load(f)\n",
        "\n",
        "        detections = self.detect_frames(frames)\n",
        "\n",
        "        tracks={\n",
        "            \"players\":[],\n",
        "            \"referees\":[],\n",
        "            \"ball\":[]\n",
        "        }\n",
        "\n",
        "        for frame_num, detection in enumerate(detections):\n",
        "            cls_names = detection.names\n",
        "            cls_names_inv = {v:k for k,v in cls_names.items()}\n",
        "\n",
        "            detection_supervision = sv.Detections.from_ultralytics(detection)\n",
        "\n",
        "            # Convert GoalKeeper to player object\n",
        "            for object_ind , class_id in enumerate(detection_supervision.class_id):\n",
        "                if cls_names[class_id] == \"goalkeeper\":\n",
        "                    detection_supervision.class_id[object_ind] = cls_names_inv[\"player\"]\n",
        "\n",
        "            detection_with_tracks = self.tracker.update_with_detections(detection_supervision)\n",
        "\n",
        "            tracks[\"players\"].append({})\n",
        "            tracks[\"referees\"].append({})\n",
        "            tracks[\"ball\"].append({})\n",
        "\n",
        "            for frame_detection in detection_with_tracks:\n",
        "                bbox = frame_detection[0].tolist()\n",
        "                cls_id = frame_detection[3]\n",
        "                track_id = frame_detection[4]\n",
        "\n",
        "                if cls_id == cls_names_inv['player']:\n",
        "                    tracks[\"players\"][frame_num][track_id] = {\"bbox\":bbox}\n",
        "\n",
        "                if cls_id == cls_names_inv['referee']:\n",
        "                    tracks[\"referees\"][frame_num][track_id] = {\"bbox\":bbox}\n",
        "\n",
        "            for frame_detection in detection_supervision:\n",
        "                bbox = frame_detection[0].tolist()\n",
        "                cls_id = frame_detection[3]\n",
        "\n",
        "                if cls_id == cls_names_inv['ball']:\n",
        "                    tracks[\"ball\"][frame_num][1] = {\"bbox\":bbox}\n",
        "\n",
        "\n",
        "        if stub_path is not None:\n",
        "            with open(stub_path,'wb') as f:\n",
        "                pickle.dump(tracks,f)\n",
        "\n",
        "        return tracks\n",
        "\n",
        "    def draw_ellipse(self,frame,bbox,color,track_id=None):\n",
        "        y2 = int(bbox[3])\n",
        "        x_center, _ = get_center_of_bbox(bbox)\n",
        "        width = get_bbox_width(bbox)\n",
        "\n",
        "        cv2.ellipse(\n",
        "            frame,\n",
        "            center=(x_center,y2),\n",
        "            axes=(int(width), int(0.35*width)),\n",
        "            angle=0.0,\n",
        "            startAngle=-45,\n",
        "            endAngle=235,\n",
        "            color = color,\n",
        "            thickness=2,\n",
        "            lineType=cv2.LINE_4\n",
        "        )\n",
        "\n",
        "        rectangle_width = 40\n",
        "        rectangle_height=20\n",
        "        x1_rect = x_center - rectangle_width//2\n",
        "        x2_rect = x_center + rectangle_width//2\n",
        "        y1_rect = (y2- rectangle_height//2) +15\n",
        "        y2_rect = (y2+ rectangle_height//2) +15\n",
        "\n",
        "        if track_id is not None:\n",
        "            cv2.rectangle(frame,\n",
        "                          (int(x1_rect),int(y1_rect) ),\n",
        "                          (int(x2_rect),int(y2_rect)),\n",
        "                          color,\n",
        "                          cv2.FILLED)\n",
        "\n",
        "            x1_text = x1_rect+12\n",
        "            if track_id > 99:\n",
        "                x1_text -=10\n",
        "\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"{track_id}\",\n",
        "                (int(x1_text),int(y1_rect+15)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.6,\n",
        "                (0,0,0),\n",
        "                2\n",
        "            )\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def draw_traingle(self,frame,bbox,color):\n",
        "        y= int(bbox[1])\n",
        "        x,_ = get_center_of_bbox(bbox)\n",
        "\n",
        "        triangle_points = np.array([\n",
        "            [x,y],\n",
        "            [x-10,y-20],\n",
        "            [x+10,y-20],\n",
        "        ])\n",
        "        cv2.drawContours(frame, [triangle_points],0,color, cv2.FILLED)\n",
        "        cv2.drawContours(frame, [triangle_points],0,(0,0,0), 2)\n",
        "\n",
        "        return frame\n",
        "    def draw_team_ball_control(self,frame,frame_num,team_ball_control):\n",
        "        # Draw a semi-transparent rectaggle\n",
        "        overlay = frame.copy()\n",
        "        cv2.rectangle(overlay, (1350, 850), (1900,970), (255,255,255), -1 )\n",
        "        alpha = 0.4\n",
        "        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
        "\n",
        "        team_ball_control_till_frame = team_ball_control[:frame_num+1]\n",
        "        # Get the number of time each team had ball control\n",
        "        team_1_num_frames = team_ball_control_till_frame[team_ball_control_till_frame==1].shape[0]\n",
        "        team_2_num_frames = team_ball_control_till_frame[team_ball_control_till_frame==2].shape[0]\n",
        "        team_1 = team_1_num_frames/(team_1_num_frames+team_2_num_frames)\n",
        "        team_2 = team_2_num_frames/(team_1_num_frames+team_2_num_frames)\n",
        "\n",
        "        cv2.putText(frame, f\"Team 1 Ball Control: {team_1*100:.2f}%\",(1400,900), cv2.TIMES_NEW_ROMAN, 1, (0,0,0), 3)\n",
        "        cv2.putText(frame, f\"Team 2 Ball Control: {team_2*100:.2f}%\",(1400,950), cv2.TIMES_NEW_ROMAN, 1, (0,0,0), 3)\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def draw_annotations(self, video_frames, tracks, team_ball_control):\n",
        "        output_video_frames = []\n",
        "        for frame_num, frame in enumerate(video_frames):\n",
        "            frame = frame.copy()\n",
        "\n",
        "            if frame_num < len(tracks[\"players\"]):  # Check if frame_num is within bounds\n",
        "                player_dict = tracks[\"players\"][frame_num]\n",
        "                ball_dict = tracks[\"ball\"][frame_num]\n",
        "                referee_dict = tracks[\"referees\"][frame_num]\n",
        "\n",
        "                for track_id, player in player_dict.items():\n",
        "                    color = player.get('team_color',(0,0,225))\n",
        "                    frame = self.draw_ellipse(frame, player['bbox'], color, track_id)\n",
        "\n",
        "                    if player.get('has_ball',False):\n",
        "                        frame = self.draw_traingle(frame, player[\"bbox\"],(0,0,255))\n",
        "                for _, referee in referee_dict. items ():\n",
        "                    frame = self. draw_ellipse(frame, referee[\"bbox\"], (0,255, 255))\n",
        "                for track_id, ball in ball_dict.items():\n",
        "                    frame = self.draw_traingle(frame, ball[\"bbox\"],(0,255,0))\n",
        "\n",
        "                # Draw Team Ball Control\n",
        "                frame = self.draw_team_ball_control(frame, frame_num, team_ball_control)\n",
        "\n",
        "            output_video_frames.append(frame)\n",
        "\n",
        "        return output_video_frames\n"
      ],
      "metadata": {
        "id": "_CrGavS_Fjpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main\n",
        "---\n",
        "Orchestrates the entire process of analyzing a soccer match video, including object detection, object tracking, color assignment, player-ball assignment, and visualization\n"
      ],
      "metadata": {
        "id": "PcXX932aFJBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    video_frames = read_video('Soccer1.mp4')\n",
        "    tracker = Tracker('best-4.pt')\n",
        "    tracks = tracker.get_object_tracks(video_frames,\n",
        "                                        read_from_stub=True,\n",
        "                                       stub_path='stubs/track_stubs.pkl')\n",
        "    for track_id, player in tracks['players'][0].items():\n",
        "        bbox = player['bbox']\n",
        "        frame = video_frames[0]\n",
        "        # crop bbox from frame\n",
        "        cropped_image = frame[int(bbox[1]):int (bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "        # save the cropped image\n",
        "        cv2.imwrite('stubs/cropped_image.jpg', cropped_image)\n",
        "\n",
        "    tracks[\"ball\"] = tracker.interpolate_ball_positions(tracks[\"ball\"])\n",
        "\n",
        "    team_assigner = TeamAssigner()\n",
        "    team_assigner.assign_team_color(video_frames[0],\n",
        "                                    tracks['players'][0])\n",
        "\n",
        "    for frame_num, player_track in enumerate(tracks['players']):\n",
        "        for player_id, track in player_track.items():\n",
        "            team = team_assigner.get_player_team(video_frames[frame_num],\n",
        "                                                track['bbox'],\n",
        "                                                player_id)\n",
        "            tracks['players'][frame_num][player_id]['team'] = team\n",
        "            tracks['players'][frame_num][player_id]['team_color'] = team_assigner.team_colors[team]\n",
        "\n",
        "    player_assigner =PlayerBallAssigner()\n",
        "    team_ball_control= []\n",
        "    for frame_num, player_track in enumerate(tracks['players']):\n",
        "        ball_bbox = tracks['ball'][frame_num][1]['bbox']\n",
        "        assigned_player = player_assigner.assign_ball_to_player(player_track, ball_bbox)\n",
        "\n",
        "        if assigned_player != -1:\n",
        "            tracks['players'][frame_num][assigned_player]['has_ball'] = True\n",
        "            team_ball_control.append(tracks['players'][frame_num][assigned_player]['team'])\n",
        "        else:\n",
        "            team_ball_control.append(team_ball_control[-1])\n",
        "    team_ball_control= np.array(team_ball_control)\n",
        "\n",
        "    output_video_frames = tracker.draw_annotations(video_frames, tracks, team_ball_control)\n",
        "\n",
        "\n",
        "\n",
        "    save_video(output_video_frames,'ouput_3.avi')"
      ],
      "metadata": {
        "id": "W-8bhryAE7j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "ka2LRDtQH6Aq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}